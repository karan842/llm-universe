{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make torch deterministic\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Load the MNIST test set\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Define the device\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedVerySimpleNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1=100, hidden_size_2=100):\n",
    "        super(QuantizedVerySimpleNet, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "    \n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.quant(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = QuantizedVerySimpleNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedVerySimpleNet(\n",
       "  (quant): QuantStub()\n",
       "  (linear1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (linear2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.qconfig = torch.ao.quantization.get_default_qconfig\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute '_fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m net_quantized \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mao\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_qat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      2\u001b[0m net_quantized\n",
      "File \u001b[1;32md:\\Program Files\\conda\\envs\\llm-env\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:494\u001b[0m, in \u001b[0;36mprepare_qat\u001b[1;34m(model, mapping, inplace)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[0;32m    492\u001b[0m     model \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model)\n\u001b[1;32m--> 494\u001b[0m \u001b[43mpropagate_qconfig_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqconfig_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m convert(model, mapping\u001b[38;5;241m=\u001b[39mmapping, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, remove_qconfig\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    496\u001b[0m prepare(model, observer_non_leaf_module_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m(mapping\u001b[38;5;241m.\u001b[39mvalues()), inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Program Files\\conda\\envs\\llm-env\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:126\u001b[0m, in \u001b[0;36mpropagate_qconfig_\u001b[1;34m(module, qconfig_dict, prepare_custom_config_dict)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prepare_custom_config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     prepare_custom_config_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 126\u001b[0m \u001b[43m_propagate_qconfig_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepare_custom_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepare_custom_config_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program Files\\conda\\envs\\llm-env\\lib\\site-packages\\torch\\ao\\quantization\\quantize.py:92\u001b[0m, in \u001b[0;36m_propagate_qconfig_helper\u001b[1;34m(module, qconfig_dict, qconfig_parent, prefix, prepare_custom_config_dict)\u001b[0m\n\u001b[0;32m     88\u001b[0m module_qconfig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqconfig\u001b[39m\u001b[38;5;124m'\u001b[39m, module_qconfig)\n\u001b[0;32m     90\u001b[0m torch\u001b[38;5;241m.\u001b[39mao\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mqconfig\u001b[38;5;241m.\u001b[39m_assert_valid_qconfig(module_qconfig, module)\n\u001b[1;32m---> 92\u001b[0m qconfig_with_device_check \u001b[38;5;241m=\u001b[39m \u001b[43m_add_module_to_qconfig_obs_ctr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_qconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m module\u001b[38;5;241m.\u001b[39mqconfig \u001b[38;5;241m=\u001b[39m qconfig_with_device_check\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n",
      "File \u001b[1;32md:\\Program Files\\conda\\envs\\llm-env\\lib\\site-packages\\torch\\ao\\quantization\\qconfig.py:477\u001b[0m, in \u001b[0;36m_add_module_to_qconfig_obs_ctr\u001b[1;34m(qconfig, module)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_add_module_to_qconfig_obs_ctr\u001b[39m(\n\u001b[0;32m    462\u001b[0m         qconfig: QConfigAny,\n\u001b[0;32m    463\u001b[0m         module: Optional[nn\u001b[38;5;241m.\u001b[39mModule]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"This is a helper function for use in quantization prepare that updates a qconfig so that\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    the constructors stored in the qconfig will create observers on the same device that\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    'module' is on. This is intended to be used when the qconfigs are propagated to each\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m        qconfig: configured so that obs constructors set to construct on the same device as module\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m qconfig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mqconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fields\u001b[49m \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m qconfig\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_factory_kwargs_based_on_module_device\u001b[39m():\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute '_fields'"
     ]
    }
   ],
   "source": [
    "net_quantized = torch.ao.quantization.prepare_qat(net) \n",
    "net_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
